{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91fd273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) (Optional) Mount Google Drive to persist checkpoints\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except Exception as e:\n",
    "    print('Not running in Colab or drive mount failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadcdeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Clone the repository (or pull if already present)\n",
    "import os, subprocess, sys\n",
    "if not os.path.exists('270FT'):\n",
    "    subprocess.check_call([sys.executable, '-m', 'git', 'clone', 'https://github.com/oleeveeuh/270FT.git'])\n",
    "else:\n",
    "    print('Repository already exists; fetching latest changes')\n",
    "    try:\n",
    "        subprocess.check_call(['git', '-C', '270FT', 'pull'])\n",
    "    except Exception as e:\n",
    "        print('git pull failed:', e)\n",
    "# Change working directory to repo root\n",
    "os.chdir('270FT')\n",
    "print('CWD:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Install required Python packages (may take a few minutes).\n",
    "# Install core packages first, then attempt bitsandbytes which may need a matching CUDA runtime.\n",
    "!pip install -q transformers datasets peft evaluate pyyaml huggingface_hub wandb\n",
    "# Try to install bitsandbytes; if it fails, you can retry with a wheel matching the runtime's CUDA\n",
    "try:\n",
    "    get_ipython().system('pip install -q bitsandbytes')\n",
    "    print('bitsandbytes installed')\n",
    "except Exception as e:\n",
    "    print('bitsandbytes install failed (you may still proceed if using a different runtime):', e)\n",
    "# Show GPU info if available\n",
    "!nvidia-smi || true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d34f81",
   "metadata": {},
   "source": [
    "If `bitsandbytes` or other installs fail due to CUDA mismatches, try switching the Colab runtime GPU type (or use a notebook with a supported CUDA version). You can also skip installing `bitsandbytes` if you only want CPU runs, but the full QLoRA workflow requires a CUDA GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171da73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) (Optional) Preprocess raw data into processed JSONL files.\n",
    "# This will create/update data/processed/train.jsonl, validation.jsonl, and test.jsonl\n",
    "!python preprocess/load_and_prepare.py --raw_dir data/raw --processed_dir data/processed --validation_split 0.15 --test_split 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) (Optional) Inspect processed files sizes and line counts\n",
    "!ls -lh data/processed || true\n",
    "!wc -l data/processed/*.jsonl || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e16ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Provide Hugging Face token (if required).\n",
    "# Use this cell to securely input a token if you need to access gated models.\n",
    "from getpass import getpass\n",
    "token = getpass('Hugging Face token (leave blank if not needed): ')\n",
    "import os\n",
    "if token:\n",
    "    os.environ['HF_TOKEN'] = token\n",
    "    # Also login via huggingface-cli for convenience\n",
    "    try:\n",
    "        get_ipython().system('huggingface-cli login --token \"$HF_TOKEN\"')\n",
    "    except Exception as e:\n",
    "        print('Automatic huggingface-cli login failed; token stored in HF_TOKEN')\n",
    "    print('HF_TOKEN set in environment')\n",
    "else:\n",
    "    print('No token provided; proceeding without HF token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6b) Disable W&B interactive logging to avoid login prompts during automated runs\n",
    "import os\n",
    "os.environ['WANDB_MODE'] = 'offline'\n",
    "print('W&B offline mode set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eaf17e",
   "metadata": {},
   "source": "Now run the full training script below. The script `training/train_dual_lora.py` will look for `data/processed/train.jsonl`, `validation.jsonl`, and `test.jsonl` in `data/processed` and will use the models listed in `configs/training_config.yaml`.\n\n**Note about test data**: The test set is reserved for human-in-the-loop evaluation after training. During training, only the validation set is used for evaluation metrics. The training will log:\n- **Training loss** every 10 steps\n- **Validation loss** at the end of each epoch\n- Metrics to W&B (if enabled) or console output"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Run the training script (this will start QLoRA fine-tuning).\n",
    "# Note: training will log to W&B if enabled in the config; we set W&B to offline above to avoid interactive prompts.\n",
    "# Use unbuffered output so logs stream in Colab\n",
    "!python -u training/train_dual_lora.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2214c4f",
   "metadata": {},
   "source": "**Training Monitoring:**\nThe training script logs losses and metrics in multiple ways:\n1. **Console output**: Training loss logged every 10 steps, validation metrics at each epoch\n2. **W&B (if enabled)**: Full training/validation curves, model checkpoints\n3. **Checkpoints**: Saved every 500 steps to the output directory (keeping last 3)\n\n**Troubleshooting tips:**\n- If you see `FileNotFoundError` complaining about missing `test.jsonl`, re-run the preprocessing cell or ensure `data/processed/test.jsonl` exists.\n- If you get `bitsandbytes` import errors, try installing a different `bitsandbytes` wheel that matches the Colab CUDA runtime or switch runtime.\n- If training runs out of VRAM, reduce `batch_size` in `configs/training_config.yaml` or switch to a larger GPU.\n- If you prefer to persist checkpoints to Google Drive, create a folder in Drive and update `configs/training_config.yaml` output paths to point inside `/content/drive/MyDrive/...`.\n\n**Next steps after training:**\n- Run inference on test questions using the trained adapter\n- Use human-in-the-loop review to evaluate the quality of generated solutions\n- The test set at `data/processed/test.jsonl` contains questions without solutions (intentional for unbiased evaluation)"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}